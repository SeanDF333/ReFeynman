# ReFeynman Training Configuration

model:
  base_model: "Qwen/Qwen2.5-7B-Instruct"
  max_seq_length: 2048
  load_in_4bit: true
  
lora:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.05
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj
  bias: "none"
  task_type: "CAUSAL_LM"

sft:
  num_epochs: 3
  batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2.0e-4
  warmup_steps: 100
  logging_steps: 10
  save_steps: 200
  max_grad_norm: 0.3
  weight_decay: 0.001

grpo:
  num_iterations: 5
  num_samples_per_prompt: 4
  batch_size: 2
  learning_rate: 5.0e-6
  kl_coef: 0.05
  clip_range: 0.2
  gamma: 1.0
  reward_scale: 1.0

data:
  train_size: 1000
  eval_size: 100
  seed_examples: 50

paths:
  data_dir: "./data"
  output_dir: "./checkpoints"
  logs_dir: "./logs"