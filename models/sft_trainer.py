"""
Supervised Fine-Tuning (SFT) è®­ç»ƒè„šæœ¬
ä½¿ç”¨LoRAåœ¨åŸºç¡€æ¨¡å‹ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒ
"""

import os
import yaml
import torch
from pathlib import Path
from datasets import load_dataset
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    TrainingArguments,
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
from trl import SFTTrainer, DataCollatorForCompletionOnlyLM
from dotenv import load_dotenv

load_dotenv()


def load_config(config_path: str = "config.yaml"):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)


def prepare_model_and_tokenizer(config):
    """å‡†å¤‡æ¨¡å‹å’Œåˆ†è¯å™¨"""
    model_name = config['model']['base_model']
    
    # 4bité‡åŒ–é…ç½®
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=config['model']['load_in_4bit'],
        bnb_4bit_quant_type="nf4",
        bnb_4bit_compute_dtype=torch.float16,
        bnb_4bit_use_double_quant=True,
    )
    
    # åŠ è½½tokenizer
    tokenizer = AutoTokenizer.from_pretrained(
        model_name,
        trust_remote_code=True,
        token=os.getenv("HF_TOKEN")
    )
    tokenizer.pad_token = tokenizer.eos_token
    tokenizer.padding_side = "right"
    
    # åŠ è½½æ¨¡å‹
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        quantization_config=bnb_config,
        device_map="auto",
        trust_remote_code=True,
        token=os.getenv("HF_TOKEN")
    )
    
    # å‡†å¤‡æ¨¡å‹ç”¨äºè®­ç»ƒ
    model = prepare_model_for_kbit_training(model)
    
    return model, tokenizer


def get_lora_config(config):
    """è·å–LoRAé…ç½®"""
    lora_cfg = config['lora']
    return LoraConfig(
        r=lora_cfg['r'],
        lora_alpha=lora_cfg['lora_alpha'],
        lora_dropout=lora_cfg['lora_dropout'],
        target_modules=lora_cfg['target_modules'],
        bias=lora_cfg['bias'],
        task_type=lora_cfg['task_type'],
    )


def format_dialogue(example, tokenizer):
    """æ ¼å¼åŒ–å¯¹è¯æ•°æ®"""
    messages = example['messages']
    
    # æ„å»ºQwenæ ¼å¼çš„å¯¹è¯
    text = ""
    for msg in messages:
        if msg['role'] == 'user':
            text += f"<|im_start|>user\n{msg['content']}<|im_end|>\n"
        elif msg['role'] == 'assistant':
            text += f"<|im_start|>assistant\n{msg['content']}<|im_end|>\n"
    
    return {"text": text}


def train_sft(config_path: str = "config.yaml"):
    """æ‰§è¡ŒSFTè®­ç»ƒ"""
    config = load_config(config_path)
    
    print("ğŸš€ Starting SFT training...")
    print(f"ğŸ“¦ Base model: {config['model']['base_model']}")
    
    # å‡†å¤‡æ¨¡å‹
    model, tokenizer = prepare_model_and_tokenizer(config)
    
    # åº”ç”¨LoRA
    lora_config = get_lora_config(config)
    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()
    
    # åŠ è½½æ•°æ®é›†
    dataset = load_dataset('json', data_files={
        'train': 'data/train.jsonl'
    })
    
    # æ ¼å¼åŒ–æ•°æ®
    dataset = dataset.map(
        lambda x: format_dialogue(x, tokenizer),
        remove_columns=dataset['train'].column_names
    )
    
    # è®­ç»ƒå‚æ•°
    sft_cfg = config['sft']
    training_args = TrainingArguments(
        output_dir=config['paths']['output_dir'] + "/sft",
        num_train_epochs=sft_cfg['num_epochs'],
        per_device_train_batch_size=sft_cfg['batch_size'],
        gradient_accumulation_steps=sft_cfg['gradient_accumulation_steps'],
        learning_rate=sft_cfg['learning_rate'],
        warmup_steps=sft_cfg['warmup_steps'],
        logging_steps=sft_cfg['logging_steps'],
        save_steps=sft_cfg['save_steps'],
        max_grad_norm=sft_cfg['max_grad_norm'],
        weight_decay=sft_cfg['weight_decay'],
        fp16=True,
        optim="paged_adamw_8bit",
        lr_scheduler_type="cosine",
        save_total_limit=3,
        logging_dir=config['paths']['logs_dir'],
        report_to="none",  # å¯æ”¹ä¸º"wandb"
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = SFTTrainer(
        model=model,
        args=training_args,
        train_dataset=dataset['train'],
        tokenizer=tokenizer,
        max_seq_length=config['model']['max_seq_length'],
        dataset_text_field="text",
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("\n" + "="*50)
    print("ğŸ¯ Starting training...")
    print("="*50 + "\n")
    
    trainer.train()
    
    # ä¿å­˜æ¨¡å‹
    final_path = config['paths']['output_dir'] + "/sft_final"
    trainer.save_model(final_path)
    tokenizer.save_pretrained(final_path)
    
    print(f"\nâœ… SFT training complete!")
    print(f"ğŸ“ Model saved to: {final_path}")
    
    return trainer


if __name__ == "__main__":
    train_sft()